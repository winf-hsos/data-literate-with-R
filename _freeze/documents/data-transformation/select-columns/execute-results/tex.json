{
  "hash": "57fbcef68bc2ed05d41d0f373ade6388",
  "result": {
    "markdown": "---\ntitle: Select columns\nexecute: \n  warning: false\n  output: false\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n:::\n\n\n\nThis chapter introduces tools to remove unnecessary columns from the data set. Or, positively stated, we learn how to specify the columns we need for our analysis. As with most data transformation operations, we mostly introduce functions from the `{dplyr}` package.\n\n## The `select` command {#sec-select-command}\n\nThe function `select()` is the designated tool to select columns with `{dplyr}`. By passing different things to the function, we can efficiently define the set of columns in the resulting data frame.\n\n## By column names\n\nThe easiest and intuitive way to specify the columns we want is by listing their names. We can pass one or more column names to the `select()` function. In case of two or more, we use commas to separate the names:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Just one column name\norders %>% \n  select(order_id)\n\n#> # A tibble: 2,874 x 1\n#>        order_id\n#>           <dbl>\n#> 1 1130007101519\n#> 2 1130014965839\n#> 3 1130026958927\n#> ...\n\n# A list of column names\norders %>% \n  select(order_id, total_price)\n\n#> # A tibble: 2,874 x 2\n#>        order_id total_price\n#>           <dbl>       <dbl>\n#> 1 1130007101519        94.7\n#> 2 1130014965839        32.2\n#> 3 1130026958927        30.2\n#> ...\n```\n:::\n\n\n\nWhen we only want a few columns, this approach works fine and is usually a good choice. I expect you apply this method in more than 90% of all cases. However, there are cases when you'd wish there was something more flexible. Luckily, there is.\n\n## By column name patterns\n\n### Names starting with a string\n\nSometimes we want to select columns based on a pattern of their names. Take the orders data set as an example. Here, all variables that contain information about the shipping address have the prefix `shipping`. We leverage this with the helper function `starts_with()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(starts_with(\"shipping\")) %>% \n  colnames()\n\n#> [1] \"shipping_address_city\"      \"shipping_address_zip\"       \"shipping_address_country\"  \n#> [4] \"shipping_address_latitude\"  \"shipping_address_longitude\"\n```\n:::\n\n\n\n### Names ending with a string\n\nSimilar to `start_with()`, the function `ends_with()` looks for a string at the end of a column name. For example, all columns that contain a date/time information in the data set end with the suffix `_at`. We can take advantage of that in case we wanted to select all theses columns efficiently:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(ends_with((\"_at\"))) %>% \n  colnames()\n\n#> [1] \"created_at\"                            \"updated_at\"               \n#> [3] \"processed_at\"                          \"customer_accepts_marketing_updated_at\"\n#> [5] \"customer_created_at\"                   \"customer_updated_at\"      \n#> [7] \"cancelled_at\"                          \"closed_at\"     \n```\n:::\n\n\n\n### Names with a string anywhere\n\nTo complete the picture, we can also search for string somewhere in a column name. The `contains()` function does exactly that:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(contains(\"price\")) %>% \n  colnames()\n\n#> [1] \"current_subtotal_price\" \"current_total_price\"    \"total_line_items_price\"\n#> [4] \"total_price\"   \n```\n:::\n\n\n\n### Complex scenarios with regular expressions\n\nIn some cases, it might not be enough to just match strings in column names. It is easy to imagine more complex patterns, involving wildcards or a specifiy order in which symbols must appear in a column name. For all this, regular expressions are a wonderful, albeit complex, solution. If you regularly encounter such complex scenarios, I recommend you familiarize yourself with the basics of regular expressions. I rarely need them myself, and if I do, I look up the expression on the internet using a good Google search.\n\nI cannot think a useful example in the context of the orders data set. However, the following regular expressions looks for the string `_at` at the end of the column name. Thus, it mirrors the example from above, but solves it with a regular expression:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(matches(\"_at$\")) %>% \n  colnames()\n\n#> [1] \"created_at\"                            \"updated_at\"            \n#> [3] \"processed_at\"                          \"customer_accepts_marketing_updated_at\"\n#> [5] \"customer_created_at\"                   \"customer_updated_at\"      \n#> [7] \"cancelled_at\"                          \"closed_at\" \n```\n:::\n\n\n\n### Combinations of patterns\n\nWe can combine the functions that look for strings in column names to create more specific pattern searches. The example below uses the `&` operator to connect two functions with a logical *and*. This means, both expressions must evaluate to *true* for the column to be selected:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(starts_with(\"customer\") & ends_with(\"_at\")) %>% \n  colnames()\n\n#> [1] \"customer_accepts_marketing_updated_at\" \"customer_created_at\"      \n#> [3] \"customer_updated_at\"\n```\n:::\n\n\n\n::: {.callout-note appearance=\"simple\" icon=\"false\"}\nIn contrast to `filter`, where a comma-separated list of expressions combines them with a logical *and*, when using this approach with `select`, the resulting columns are combined to a unified set of columns. This means a logical *or* is applied. For example, listing `starts_with(\"customer\")` and `ends_with(\"_at\")` separated by a comma keeps all columns that start with \"customer\" or that end with \"_at\".\n:::\n\n## By data type\n\nAnother flexible way to select columns is by their data type. Say we want to select all numeric columns, because we want to calculate the mean value across all of them in the next step of the pipeline. There is shortcut for this, using the `where()` function in combination with `is.numeric`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(where(is.numeric)) %>% \n  colnames()\n\n #> [1] \"order_id\"                      \"order_number\"                  \"app_id\"                \n #> [4] \"current_subtotal_price\"        \"current_total_price\"           \"current_total_discounts \n #> [7] \"current_total_duties_set\"      \"total_discounts\"               \"total_line_items_price\"  ...\n```\n:::\n\n\n\nOf course there are functions for all other data types as well:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(where(is.logical))\n\norders %>% \n  select(where(is.character))\n\norders %>% \n  select(where(is.factor))\n\norders %>% \n  select(where(is.list))\n\n# The package lubridate provides a function to check for date (without time) ...\norders %>% \n  select(where(lubridate::is.Date))\n\n# ... and one for date with time\norders %>% \n  select(where(lubridate::is.POSIXct))\n```\n:::\n\n\n\n## By position\n\nAnother way we can address columns is by their position or index.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select last column\norders %>% \n  select(last_col())\n\n# Select last second last column \norders %>% \n  select(last_col(2))\n\n# Select first column\norders %>% \n  select(1)\n\n# Select a range of columns\norders %>% \n  select(2:6)\n\n# Select everything but the last two columns\norders %>% \n  select(1:last_col(2))\n```\n:::\n\n\n\n## By set affiliation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define a set of columns in a vector and select this set\ncols <- c(\"created_at\", \"updated_at\")\n\norders %>% \n  select(all_of(cols))\n\n#> # A tibble: 2,874 x 2\n#>   created_at          updated_at         \n#>   <dttm>              <dttm>             \n#> 1 2019-05-24 12:59:16 2019-06-19 13:23:26\n#> 2 2019-05-24 13:09:08 2019-06-21 14:40:07\n#> 3 2019-05-24 13:22:41 2019-06-21 12:35:23\n#> ...\n```\n:::\n\n\n\n## Exclude columns\n\nThe previous sections introduced ways to select columns, that is, specifying what we *want*. Sometimes it is more efficient to tell R what we *don't want*. The minus sign `-` negates any selection from the previous sections. The following command gives us all columns _except_ the `order_id`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(-order_id)\n```\n:::\n\n\n\nWe can combine positive and negative selections as we need:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\norders %>% \n  select(ends_with(\"_at\"), -closed_at, -processed_at) %>% \n  colnames()\n\n#> [1] \"created_at\"                            \"updated_at\"            \n#> [3] \"customer_accepts_marketing_updated_at\" \"customer_created_at\"      \n#> [5] \"customer_updated_at\"                   \"cancelled_at\"   \n```\n:::\n",
    "supporting": [
      "select-columns_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}